


<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>

  <meta name="viewport" content="width=500">
  <link href="stylesheet.css" rel="stylesheet" type="text/css">
  <link rel="icon" type="image/png" href="images/favicon.ico">
  <title>Manasi Sharma, Stanford University</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  <link rel="shortcut icon" type="image/jpg" href="favicon2.jpg">
</head>

<body>
  <table width="1000" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <!--<name>Manasi Sharma</name>-->
                <head>
                  <h1>Manasi Sharma</h1>
                </head>
              </p>
              <!-- About -->
              <p>
                <!-- <b>Hi there!</b> I am a second year MS student in Computer Science at Stanford University on the Artificial Intelligence track. I am currently member of the <a href="https://svl.stanford.edu/">Stanford Vision Lab</a> under <a href="https://profiles.stanford.edu/fei-fei-li">Prof. Fei-Fei Li</a> and <a href="https://jiajunwu.com/">Prof. Prof. Jiajun Wu</a>, where I work on the <a href="https://sites.google.com/view/behavior-1k">BEHAVIOR</a> project in robotic simulation benchmarking and the <a href="https://github.com/corgiTrax/AIDA">ADDA</a> (Attention-driven data augmentation) project which aims to improve image classification performance using a saliency-map based augmentation. I consider myself a generalist in AI and am interested in the broad domains of Deep Learning, Computer Vision, Explainability, Reinforcement Learning & Decision Making, Graph Neural Networks. I have also recently joined the ILIAD Lab under Prof. Dorsa Sadigh, and I am heading a new project on 'Gaze & Language-assisted Instruction Corrections for Imitation Learning'. -->
                <b>Hi there!</b> I am a recent graduate from Stanford University year (Master's in Computer Science on the Artificial Intelligence track) and I completed my undergraduate program at Columbia University in Computer Science and Physics! I consider myself a generalist - I have broad experience applying AI in a broad set of domains, from astronomy to autonomous vehicles, and I am now really passionate about bringing the power of Large Language Models and other similar foundation models to enterprises and making them for robust for use. 

                <!-- I am also very interested in the applications of perception-based systems and AI to a variety of scenarios, from Astronomy to Autonomous Systems. -->
            </p>
            <p>
              <b>Research: </b> I am currently member of the <a href="https://iliad.stanford.edu/">ILIAD</a> under <a href="https://dorsa.fyi/">Prof. Dorsa Sadigh</a>, in which I am currently working on two projects - 1) Language-Conditioned Diffusion Models for Shared Autonomy 2) Large Language Models as Trajectory Labelers. In the past, I also worked in the <a href="https://svl.stanford.edu/">Stanford Vision Lab</a> under <a href="https://profiles.stanford.edu/fei-fei-li">Prof. Fei-Fei Li</a> and <a href="https://jiajunwu.com/">Prof. Prof. Jiajun Wu</a>, on the <a href="https://sites.google.com/view/behavior-1k">BEHAVIOR</a> project in robotic simulation benchmarking, in which I worked on assembling action, goal, etc. labels for demonstrations. 
            </p>
            <p>
              <b>Teaching: </b> I have also been a TA for some of the most popular courses at Stanford, and they have been some of the most rewarding experiences of my college career, from Fei-Fei Li's <a href="http://cs231n.stanford.edu/">Computer Vision</a> course to Andrew Ng's <a href="https://cs230.stanford.edu/">Deep Learning</a> class (you should also hopefully be able to see my public tutorial for the <a href="https://web.stanford.edu/class/cs224n/">Natural Language Processing</a> course on YouTube soon!)
            </p>
            <p>
              <b>Internship: </b> During the summer of 2022, I also interned in the Autonomous Vehicles team at Nissan, in which I worked on assembling a LiDAR only classification system for road objects! I sought an experience in which I was able to make a significant contribution (forgoing other offers, eg. Amazon), was very happy that the experience turned out well and my classification had been deployed in the AV fleet at Nissan last winter!
            </p>
            <p>
              <b>Everything else: </b> Outside of work, I love dancing (I was Captain of a Raas team (Indian folk dance) at Columbia, you can check us out <a href="https://www.youtube.com/watch?v=ikRqESbMFFA">here</a>), playing the keyboard and in the vein of having moved to the Bay Area, I enjoy going on hikes (Vasona Park ftw!)
            </p>

            <p>
              <b>Undergraduate Experience: </b> I graduated in 2021 from Columbia University with a Bachelor's degree in Computer Science and Physics. As an undergrad, I was supervised by <a href="https://www.cs.columbia.edu/~djhsu/"> Prof. Daniel Hsu</a> and <a href="https://datascience.columbia.edu/people/zoltan-haiman/"> Prof. Zoltan Haiman</a> on interpreting astrophysical deep learning models for weak lensing using an array of saliency map methods. I started off my undergraduate program with a broad interest in computational physics and first pursued the direction of AI at Caltech in 2019, under <a href="https://sites.astro.caltech.edu/~mansi/"> Prof. Mansi Kasliwal </a> in which I developed a real/bogus image astrophysical source classifier for the IR-Gattini telescope that performed so well that it was permanently included in the telescope's data processing pipeline. 
            </p>
            <p>
              As I entered graduate school, unfulfilled by the relatively potentially impact astrophysics can have on current-life and real-world affairs, my interest in AI broadened to 
              include more real-world applications that had a greater focus on human and human-computer interaction, such as LLMs and AVs. 
            </p>
            <p>
              <b>Areas of Experience: </b> Deep Learning, Natural Language Processing, Computer Vision, Diffusion Models, Explainability, Reinforcement Learning & Decision Making, Robotics, & Graph Neural Networks.
            </p>
           
              <!-- Contact details -->
              <p align=center>
                <a href="mailto:manasis@stanford.edu">Email</a> &nbsp/&nbsp
                <a href="Resume_Manasi_Sharma.pdf">CV</a> &nbsp/&nbsp
                <a href="https://github.com/manasi-sharma">Github</a> &nbsp/&nbsp
                <a href="https://bit.ly/3PsYx2c">Google Scholar</a> &nbsp/&nbsp
                <!-- <a href="https://arxiv.org/a/jena_r_1.html">ArXiv</a>&nbsp/&nbsp -->
                <a href="https://www.linkedin.com/in/manasi1/">LinkedIn </a> &nbsp/&nbsp
                <a href="https://twitter.com/ManasiSharma_">Twitter </a>
              </p>

            </td>
            <td width="83%">
            <img width="160%" style="border-radius: 100%;" src="DSC_8396.JPG">

              </td>
          </tr>
        </table>


          <!-- Education -->
          <table width="100%" align="center" border="0" cellspacing="0"> <!--cellpadding="20">-->
            <tr>
              <td>
                <!-- <heading>Publications</heading> -->
                <head>
                  <h1>Education</h1>
                </head>
              </td>
            </tr>
          </table>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td width="25%">
               <img width="90%" src="stanford_smaller.png" alt="obj">
              </td>
                <br>
               <td valign="middle" width="75%">
                <head>
                  <h3>Stanford University, School of Engineering </a> </h3>
                </head>
                Master's in Computer Science with a Research Distinction (Thesis)
                <br>
                Graduated in June 2023
                <br>
                Advisors: Dorsa Sadigh (ILIAD Lab), Fei-Fei Li, Jiajun Wu (Stanford Vision Lab)
              </td>
            </tr>

            <tr>
              <td width="25%">
               <img width="90%" src="columbia.png" alt="obj">
              </td>
                <br>
               <td valign="middle" width="75%">
                <head>
                  <h3>Columbia University, Columbia College </a> </h3>
                </head>
                BA in Computer Science (major) and Physics (minor)
                <br>
                Graduated in May 2021
                <br>
                Advisors: Daniel Hsu, Zoltan Haiman
              </td>
            </tr>
  
          </table>



          <!-- Professional Exp -->
        <table width="100%" align="center" border="0" cellspacing="0"> <!--cellpadding="20">-->
          <tr>
            <td>
              <!-- <heading>Publications</heading> -->
              <head>
                <h1>Professional / Research Experience</h1>
              </head>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          
        <!-- <tr>
            <td>
              <head>
                <h1>Professional / Research Experience</h1>
              </head>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"> -->
          
          <tr>
            <td width="25%">
             <img width="90%" src="iliad.jpg" alt="obj">
            </td>
              <br>
             <td valign="middle" width="75%">
              <head>
                <h3>Stanford University, <a href="https://iliad.stanford.edu/"> ILIAD Lab </a> </h3>
                <h5>[Oct 2022 -- present]</h5>
              </head>
              <br>
              <li> Co-leading a project on creating a framework for the use of diffusion models for trajectory generation (producting the next action a robot should take) conditioned on a language instruction input (eg. "go left"), in a shared autonomy setup (output is a combination of the robot's and human's action). </li>
              <li> Working on another project on using LLMs as zero-shot labelers of patterns in trajectory data (eg. directions or curvature). </li>
            </td>
          </tr>
          
          <tr>
            <td width="25%">
             <img width="90%" src="pearvc.jpg" alt="obj">
            </td>
              <br>
             <td valign="middle" width="75%">
              <head>
                <h3>Pear VC <a href="https://pear.vc/garage/"> </a> </h3>
                <h5>[Oct 2022 -- Jun 2023]</h5>
              </head>
              <br>
              <li> Member of the Pear Garage cohort (one 25 entrepreneurial engineering students who work on meaningful problems and build products to solve them), attended many networking and build sessions with VCs and investors in the generative AI space. </li>
              <!-- <li> Video for car classification linked <a href="demot94.mp4">here</a>. </li> -->
            </td>
          </tr>

          <tr>
            <td width="25%">
             <img width="90%" src="ailsv.jpg" alt="obj">
            </td>
              <br>
             <td valign="middle" width="75%">
              <head>
                <h3>Nissan-Renault-Mitsubishi: Alliance Innovation Laboratory <a href="https://www.ail-sv.com/"> (AIL-SV) </a> </h3>
                <h5>[June 2022 -- Sep 2022]</h5>
              </head>
              <br>
              <li> Internship in the Autonomous Vehicles team at Nissan. </li>
              <li> Implemented LiDAR point-cloud classification using the 'SimpleView' supervised learning algorithm, which projects a 3D point-cloud onto the 6 2D frames and passes it through a CNN (ResNet backbone). </li>
              <li> The model was able to classify cars, pedestrians, cyclists and vegetation with over 95% accuracy on real-world data and within the 10 Hz LiDAR processor timeframe. </li>
              <li> Experimented with a number of architechtures including Graph-based methods like Grid-GCN and point-wise MLP methods like PointNet++, finally settling on the lightweight convolution based method SimpleView. </li>
              <li> LiDAR point-cloud classification is exceedingly difficult and I encountered numerous challenges-- I was finally able to improve model performance and speed by sparisfying the network, using saliency-based weight-freezing and training on hard-negative samples. </li>
              <li> <b> The model has been deployed in Nissan Autonomous Vehicles since Winter '22.</b> </li>
              <!-- <li> Video for car classification linked <a href="demot94.mp4">here</a>. </li> -->
            </td>
          </tr>
          
          <tr>
            <td width="25%">
             <img width="90%" src="wics.jpg" alt="obj">
            </td>
              <br>
             <td valign="middle" width="75%">
              <head>
                <h3>Graduate Community Chair, <a href="https://www.stanfordwomenincomputerscience.com/team"> Stanford Woman in Computer Science </a> </h3>
                <h5>[Jun 2022 -- June 2023]</h5>
              </head>
              <br>
              <li> Organized multiple events for the graduate community including mixers, industry alumni panels, lunches, talks, etc.; spearheaded a focus on MS students through the setup of an MS student alumni panel and care-package mixer. </li>
              <li> Managed over $3000 in funds from the CS department and Engineering schools to fund events for graduate students. </li>
            </td>
          </tr>
          
          <tr>
            <td width="25%">
             <img width="90%" src="SVL.png" alt="obj">
            </td>
              <br>
             <td valign="middle" width="75%">
              <head>
                <h3>Stanford University, <a href="https://svl.stanford.edu/"> Stanford Vision Laboratory </a> </h3>
                <h5>[Oct 2021 -- June 2022]</h5>
              </head>
              <br>
              <b> BEHAVIOR Project:</b>
              <li> Led the development of the Knowledgebase for iGibson and BEHAVIOR-1K, an ImageNet-scale robotic simulation benchmark with a specifc-focus on human-relevant design. Paper accepted to the Conference of Robotics and Learning '22 and presented a talk at ECCV '22. </li>
              <li> Mobilized ~20 crowd-workers to categorize ~5000 "how-to" articles and used zero-shot Natural Language Processing techniques with GPT-3 to annotate the Virtual Reality videos and generate >97% quality activity definitions in a predicate logic-based language. </li>
              <b> ADDA (Attention-driven data augmentation):</b>
              <li> Oversaw 5 person team project on 'Modulated Attention Dropout' technique to allow for better generalization of RL policies through task-importance aware dataset augmentation. Results showed a 2% increase on baseline Behavioral Cloning results. </li>
            </td>
          </tr>
          
          <tr>
            <td width="25%">
             <img width="90%" src="dsi.png" alt="obj">
            </td>
              <br>
             <td valign="middle" width="75%">
              <head>
                <h3>Columbia University, Data Science Institute</a> </h3>
                <h5>[Sep 2019 -- June 2021]</h5>
              </head>

              <li> Under the guidance of Prof.'s Daniel Hsu and Zoltan Haiman, worked on targeting the "explainability" & trustworthiness of neural networks in the more traditional field of Astronomy. </li>
              <li> Discovered that 89% of the output of a popular neural network that uses gravitational lensing maps to predict cosmological parameters (omega_m and sigma_8) was counterintuitively attributable to negative image regions (voids, black holes, etc.) as opposed to the bright image regions (stars, galaxies, etc.). Published results in APS Physical Review '20. </li>
              <li> Also ran sanity checks on a number of popular saliency methods and found that gradient-based methods (eg. Grad-CAM / Input x Gradients, etc.) were most robust to model parameters. </li>
            </td>
          </tr>
          
          <tr>
            <td width="25%">
             <img width="90%" src="caltech.png" alt="obj">
            </td>
              <br>
             <td valign="middle" width="75%">
              <head>
                <h3>California Institute of Technology, Division of Physics, Mathematics and Astronomy</a> </h3>
                <h5>[Jun 2019 -- Aug 2019]</h5>
              </head>

              <li> Under the guidance of Prof. Mansi Kasliwal at Caltech, pioneered the development of a flagship CNN-based real/bogus image classification system for Caltech's Gattini-IR Telescope using TensorFlow (link), which achieved ~97.5% accuracy on thousands of cosmic transient sources, and published results in PASP '20. </li>
              <li> The model worked so well that it was deployed the model in the Telescope's data processing pipeline (still active), replacing the manual classification process. </li>
              <li> I also used the results of the model to identify high-confidence transient sources that I performed optical followup on by operating the 200-inch telescope at the Palomar Observatory in Southern California. </li>
            </td>
          </tr>
          
          <tr>
            <td width="25%">
             <img width="90%" src="nustar.jpg" alt="obj">
            </td>
              <br>
             <td valign="middle" width="75%">
              <head>
                <h3>Columbia University, Department of Physics</a> </h3>
                <h5>[Jun 2018 -- May 2019]</h5>
              </head>

              <li> Worked with Prof. Charles Hailey in the NuSTAR Group as a Laidlaw Research Intern. </li>
              <li> Modeled/analyzed data from NASA's NuSTAR telescope for 'AM Her' & 'HU Aqr' sources to determine key parameters such as temperature and periodicity. </li>
            </td>
          </tr>

        </table>


        <!-- Publications -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <!-- <heading>Publications</heading> -->
              <head>
                <h1>Publications</h1>
              </head>
            </td>
          </tr>
        </table>
                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="25%">
             <img width="90%" src="corl.png" alt="obj">
            </td>
              <br>
             <td valign="middle" width="75%">
               <papertitle>BEHAVIOR-1K: A Benchmark for Embodied AI with 1,000 Everyday Activities and Realistic Simulation</papertitle>

            <br>
            Chengshu Li, Cem Gokmen, ...
            <strong>Manasi Sharma...</strong>,
              <br>
              <em>Conference on Robot Learning (CoRL), 2022</em>
              <br>
              Paper link will be posted when it's made publicly available on arXiv.
              <!-- <a href="data/ipmi2019_slides.pdf">slides</a> -->
              <p></p>
              <p>We present BEHAVIOR-1K, a comprehensive simulation benchmark for human-centered robotics, motivated by the results of an extensive survey on `what do you want robots to do for you?'. It includes the definition of 1,000 everyday activities, grounded in 50 scenes (houses, gardens, restaurants, offices, etc.) with more than 3,000 objects annotated with physical and semantic properties. It also includes OmniGibson, a novel simulator that supports these activities via realistic physics simulation and rendering of rigid bodies, deformable bodies, and liquids.</p>
            </td>
          </tr>

          <tr>
            <td width="25%">
             <img width="90%" src="aps.jpg" alt="obj">
            </td>
              <br>
             <td valign="middle" width="75%">
               <papertitle>Interpreting deep learning models for weak lensing</papertitle>

            <br>
            Jose Manuel Zorrilla Matilla,
            <strong>Manasi Sharma</strong>,
            Daniel Hsu,
            Zoltan Haiman
              <br>
              <em>American Physical Society, PHYSICAL REVIEW D, 2020</em>
              <br>
                      <a href="Paper_1.pdf">Paper link</a>
        <!-- <a href="data/ipmi2019_slides.pdf">slides</a> -->
              <p></p>
              <p>Deep neural networks (DNNs) are powerful algorithms that have been proven capable of extracting non-Gaussian information from weak lensing (WL) datasets. We apply a series of well-established saliency methods to interpret the DNN and find that the most relevant pixels are those with extreme K values. For noiseless maps, regions with negative K account for 69%-89%. of the attribution of the DNN output, defined as the square of the saliency in input space. In the presence of shape noise, the attribution concentrates in high-convergence regions, with 36%-68% of the attribution in regions with highest 3rd standard deviation of K values. </p>
            </td>
          </tr>

          <tr>
            <td width="25%">
             <img width="90%" src="pasp.png" alt="obj">
            </td>
              <br>
             <td valign="middle" width="75%">
               <papertitle>Palomar Gattini-IR: Survey Overview, Data Processing System, on-Sky Performance and First Results</papertitle>

            <br>
            Kishalay De, Matthew J. Hankins, ...
            <strong>Manasi Sharma, ...</strong>,
              <br>
              <em>Publications of the Astronomical Society of the Pacific, vol. 132., 2020</em>
              <br>
                      <a href="Paper_2.pdf">Paper link</a>
        <!-- <a href="data/ipmi2019_slides.pdf">slides</a> -->
              <p></p>
              <p>Palomar Gattini-IR is a new wide-field, near-infrared (NIR) robotic time domain survey operating at Palomar Observatory. Using a 30 cm telescope mounted with a H2RG detector, Gattini-IR achieves a field of view (FOV) of 25 sq. deg. with a pixel scale of 8 7 in J-band. Here, we describe the system design, survey operations, data processing system and on-sky performance of Palomar Gattini-IR. To automatically distinguish between an astrophysical source and image subtraction artifacts, we use a ML based real-bogus (RB) classification scheme. Bogus candidates were compiled using a labeling scheme on Zooniverse, a citizen science web portal which allows set up of individual projects usually pertaining to classification and data visualization. The performance of the model was evaluated using the following metrics: accuracy on the test set of 0.975, a Matthews correlation coefficient of 0.949 and an F1 score of 0.977. </p>
            </td>
          </tr>

        </table>

          <!-- Teaching Experience -->
          <table width="100%" align="center" border="0" cellspacing="0"> <!--cellpadding="20">-->
            <tr>
              <td>
                <!-- <heading>Publications</heading> -->
                <head>
                  <h1>Teaching Experience</h1>
                </head>
              </td>
            </tr>
          </table>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td width="25%">
               <img width="90%" src="stanford_engineering.jpg" alt="obj">
              </td>
                <br>
               <td valign="middle" width="75%">
                <head>
                  <h3> Stanford School of Engineering</a> </h3>
                  <h5>[Mar 2022 -- Jun 2022]</h5>
                </head>

                Graduate Teaching Assistant
                <li> Managed weekly 'Discussion Sections' of 75+ students for some of the most popular CS courses at Stanford (>500 students); held office hours, constructed & graded HWs. Received >95% excellent reviews ('Very/Extremely Effective'). </li>
                <li> Taught and covered topics such as backpropagation, convolutional neural networks, visual transformers & attention, RNNs, YOLO, object detection, etc. </li>
                <li> Courses taught: </li>
                <li> <a href="http://cs231n.stanford.edu/">CS 231N</a> (Deep Learning for Computer Vision, Prof. Fei-Fei Li) </li>
                <li> <a href="https://cs230.stanford.edu/">CS 230</a> (Deep Learning, Prof. Andrew Ng): </li>
                <li> <a href="https://web.stanford.edu/class/cs224n/">CS 224N</a> (Natural Language Processing, Prof. Chris Manning) </li>
                <li> Some wonderful feedback I received: </li>
                <li> "I specifically went to Manasi's office hours to ask conceptual related questions because she was always so good at explaining concepts. She never missed a beat and managed to answer all my
                  questions each time such that I fully understood the concept at the end." </li>
                <li> "Helpful, very clear, always willing to get back to me if she wasn't sure how to answer my questions immediately - appreciate how helpful she was!" </li>
              </td>
            </tr>
            
            <tr>
              <td width="25%">
               <img width="90%" src="columbia2.png" alt="obj">
              </td>
                <br>
               <td valign="middle" width="75%">
                <head>
                  <h3> Columbia University, MATH 1201-1202 (Calculus III and IV)</a> </h3>
                  <h5>[Mar 2022 -- Jun 2022]</h5>
                </head>

                Columbia University, Department of Mathematics
                <li> Graded assignments, led weekly office hours, etc., for ~150 students in the undergraduate Calculus III class. Consistently received >80% excellent reviews. </li>
                <li> Taught and covered topics such as multiple integrals, Green's theorem, vector calculus, Fourier analysis, etc. </li>
              </td>
            </tr>  
          </table>






        <!-- Blog -->   
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
              <td style="padding: 20px; width: 100% ; vertical-align: middle;">
                  <head>
                    <h1>AI Blog-- Manasi's Musings</h1>
                  </head>
                  <p>
                      <ul id="news">
                          <head>
                            <h5>[June 2022 -- present]</h5>
                          </head>

                          <li> In the summer of 2022, I started writing a bi/tri-weekly blog called 'Manasi's Musings' about an array of topics, from my personal journey to my thoughts on LiDAR vs. camera data in AVs to robotic benchmarking, etc. The goal is to cover a sub-topic or question of interest in bite-sized pieces, a maximum 3 min read. The readers are currently mostly friends, colleagues and peers in my network but I hope to reach a wider audience through social media. I started the blog as I missed the process of writing-- I had actually maintained an Astrophysics blog during my high school and early undergraduate program, but stopped due to the commitments of completing my degree. I am so excited to restart, and you can check it out <a href="https://manasis8.wixsite.com/website">here</a>! </li>
                        </ul>
                    </p>
                </td>
            </tr>
        </table>
        <img width="100%" src="blog.png" alt="blog"> -->


        <!-- Course Projects -->        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
              <td style="padding: 20px; width: 100% ; vertical-align: middle;">
                  <!-- <heading>Updates</heading> -->
                  <head>
                    <h1>Stanford Course Projects</h1>
                  </head>
                  <p>
                      <ul id="news">
                          <head>
                            <h3> Crowd Aware Intent-based Reinforcement Learning - CS333 (Algorithms for Interactive Robotics)</a> </h3>
                            <h5> Winter '22</h5>
                          </head>

                          <li> Reduced collision rate in crowd navigation by 50% by leveraging human latent intent reinforcement learning <a href="https://github.com/saksham36/LatentCrowdNav">(link)</a>.</li>
                          

                          <head>
                            <h3> Predicting Drug Interactions with Graph Neural Networks - CS224W (Machine Learning with Graphs)</a> </h3>
                            <h5> Fall '21</h5>
                          </head>

                          <li> Used the Graph Isomorphism Network to exceed 11th place on ogbl-ddli leaderboard (<a href="https://github.com/manasi-sharma/cs224w-ogbl-ddi">link</a>, selected for course <a href="https://medium.com/stanford-cs224w/predicting-drug-interactions-with-graph-neural-networks-f63aab06b0b">website</a>).</li>
                          

                          <head>
                            <h3> Debiasing Models for Out-of-domain Generalization - CS224N (NLP for Deep Learning)</a> </h3>
                            <h5> Winter '22</h5>
                          </head>

                          <li> Exceeded BERT's performance on out-of-domain question-answering data by 2.5% by using debiasing models <a href="https://web.stanford.edu/class/cs224n/reports/default_116826956.pdf">(link)</a>.</li>
                          

                          <head>
                            <h3> Optimizing Wind Turbine Placement Subject to Turbine Wakes - CS238 (Decision Making Under Uncertainty)</a> </h3>
                            <h5> Fall '21</h5>
                          </head>

                          <li> Applied Q-Learning to windfarms to generate sensible layouts that maximize power, subject to wake constraints <a href="https://github.com/manasi-sharma/cs238-windfarm">(link)</a>.</li>
                          

                          <head>
                            <h3> LIMES: LIME for Image Segmentation - CS329T (Trustworthy Machine Learning)</a> </h3>
                            <h5> Spring '22</h5>
                          </head>

                          <li> Devised a LIME algorithm variant for facial segmentation that achieves explainability like gradient-based methods.</li>
                          

                          <head>
                            <h3> Monte-Carlo Tree Search Player - CS227B (General Game Playing)</a> </h3>
                            <h5> Spring '22</h5>
                          </head>

                          <li> Designed a player to play any game, using MCTS, multi-threating, grounding, etc.; placed 8th in the class <a href="https://github.com/manasi-sharma/ggp_team_rocket">(link)</a>.</li>
                        </ul>
                    </p>
                </td>
            </tr>


      <!-- Honors -->
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <td style="padding: 20px; width: 100% ; vertical-align: middle;">
                <!-- <heading>Updates</heading> -->
                <head>
                  <h1>Honors & Awards</h1>
                </head>
                <p>
                    <ul id="news">
                        <li> 1 of 18 accepted to the GFSD (Graduate Fellowships for STEM Diversity) Program.                -- <em>[Mar '22]</em></li>
                        <li> 1 of 50 accepted into Google's CS Research Mentorship Program (CSRMP), Class of 2022A.         -- <em>[Feb '22]</em></li>
                        <li> Selected for the final round of the GEM Fellowship.                                            -- <em>[Jan '22]</em></li>
                        <li> Dean's List (in 6 out of 7 graded semesters, awarded to top 20%), Columbia University.         -- <em>[Fall '17 - Fall '20]</em></li>
                        <li> Columbia Undergraduate Research Fellowship (URF), Columbia College Summer Funding Program.     -- <em>[May '20]</em></li>
                        <li> Visiting Undergraduate Research Program (VURP) Award, California Institute of Technology.      -- <em>[May '19]</em></li>
                        <li> 1 of 25 awarded Laidlaw Undergraduate Research & Leadership Scholarship, Columbia University.  -- <em>['18 - '19]</em></li>
                        <li> Andy Grove Scholarship for Intel Employees' Children, Intel Foundation.                        -- <em>[Feb '19]</em></li>
                      </ul>
                  </p>
              </td>
          </tr>
      </table>

      <!-- Leadership Roles and Extra-curriculars -->
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <td style="padding: 20px; width: 100% ; vertical-align: middle;">
                <!-- <heading>Updates</heading> -->
                <head>
                  <h1>Leadership Roles and Extra-curriculars</h1>
                </head>
                <p>
                    <ul id="news">
                      <li> Graduate Community Chair, Women in Computer Science, Stanford University.                      -- <em>[Jun '22 - present]</em></li>
                      <li> Elected as Social Chair for GradSWE, Stanford University.                                      -- <em>[Jun '22]</em></li>
                      <li> Founder & Project Leader, COVID-19 Public Hub website highlighting Columbia research.          -- <em>[Jan '22]</em></li>
                      <li> Corporate Chair, Women in Computer Science, Columbia University.                               -- <em>[Apr '20 - Jun '20]</em></li>
                      <li> Class 3 Curriculum Developer (AI section), Girls Who Code, Columbia University.                -- <em>[Feb '20 - Aug '20]</em></li>
                      <li> Executive Board UG Student Coordinator, Columbia Society for Women in Physics.                 -- <em>[Sep '18 - Sep '19]</em></li>
                      <li> Captain, 'Columbia Raas' Dance Team (member since Sep 2017), Columbia University.              -- <em>[Apr '20 - Jun '21]</em></li>
                      <li> Crew Captain, New Student Orientation Program, Columbia University.                            -- <em>[Aug '20 - Sep '20]</em></li>
                      <li> Jam Leader, Columbia Design Jam.                                                               -- <em>[May '20 - Jul '20]</em></li>
                      <li> Co-President, 'Symposium in India' Student Club, Columbia University.                          -- <em>[Sep '18 - May '19</em></li>
                      </ul>
                  </p>
              </td>
          </tr>
      </table>

      <!-- Media -->
      <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <td style="padding: 20px; width: 100% ; vertical-align: middle;">
                <head>
                  <h1>Media</h1>
                </head>
                <p>
                    <ul id="news">
                      <li> 1 of 18 accepted to the GFSD (Graduate Fellowships for STEM Diversity) Program.                -- Mar '22</li>
                      <li> 1 of 50 accepted into Google's CS Research Mentorship Program (CSRMP), Class of 2022A.         -- Feb '22</li>
                      <li> Selected for the final round of the GEM Fellowship.                                            -- Jan '22</li>
                      <li> Dean's List (in 6 out of 7 graded semesters, awarded to top 20%), Columbia University.         -- Fall '17 - Fall '20</li>
                      <li> Columbia Undergraduate Research Fellowship (URF), Columbia College Summer Funding Program.     -- May '20</li>
                      <li> Visiting Undergraduate Research Program (VURP) Award, California Institute of Technology.      -- May '19</li>
                      <li> 1 of 25 awarded Laidlaw Undergraduate Research & Leadership Scholarship, Columbia University.  -- '18 - '19</li>
                      <li> Andy Grove Scholarship for Intel Employees' Children, Intel Foundation.                        -- Feb '19</li>
                      </ul>
                  </p>
              </td>
          </tr>
      </table> -->


</body>

</html>
